---
layout: post
title: 'GANAX: A Unified MIMD-SIMD Acceleration for Generative Adverserial Networks'
date: '2018-10-16T14:24:00.000-07:00'
author: Surya Narayanan
tags: 
modified_time: '2018-10-16T20:06:27.324-07:00'
blogger_id: tag:blogger.com,1999:blog-2670908301789336410.post-66319663306013851
blogger_orig_url: https://researchdoneright.blogspot.com/2018/10/ganax-unified-mimd-simd-acceleration.html
---

<div dir="ltr" style="text-align: left;" trbidi="on">Authors:&nbsp; Amir Yazdanbakhsh, Hadi Esmaeilzadeh et. al<br />Venue: ISCA 2018<br />Link:&nbsp;https://www.cc.gatech.edu/~ayazdanb/publication/papers/ganax-isca18.pdf<br /><br />After a overwhelming number of CNN accelerator papers published in the past few years, this paper opens up a new class of networks called GANs to the architecture community. GANs, GANs comprise of two models, generative model and discriminateive model. The generative model tries to mimic the original input data, and while the discriminative model tries to predict if the generated output is original or generated. The prominent application is to build larger richer&nbsp; datasets from a small set of original dataset. Computationally, GAN's difference compared to CNN comes from the generative model, which does a "transposed" convolution. In simple terms, transposed convolution is classic convolution with alternate rows and columns of ifmap padded with zeros.&nbsp; This makes transposed convolution significantly sparse, as zeros constitute to around 60% of MAC operations.<br /><br />The main challenge in GANs comes with their "irregular sparsity". Assume a CNN dataflow where PEs are organized in 2D-arrays. A row of PE is called a Processing Vector, PV. Each PE processes a row of input and a row of filter, and the partial sums are added horizontally. Since alternating rows/columns are zeros,&nbsp; certain PE's inputs and weights are completely zeros. To overcome this, they propose to eliminate those zero-computations, and then a new issue arises. The irregularity is also maintained across outputs. That is, different PEs might have different number of zero valued rows/columns of inputs and weights. By eliminating those, the time taken for processing will vary across PEs. As a consequence the SIMD-ness property is lost. In order to overcome this, the paper proposes a 2-level MIMD-SIMD dataflow. For example, different PVs receive different set of instructions, and within a PV, all PEs receive the same set of instructions. Note that PEs receive distinct data.<br /><br />This MIMD-SIMD dataflow is achieved by two levels of mirco-op instruction buffers.<br /><br /><br /><br /><br /></div>