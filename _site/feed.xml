<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-01-26T18:05:18-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Karl’s Personal Page</title><subtitle>An array of Interests</subtitle><author><name>Karl Taht</name></author><entry><title type="html">Week 4 Recap, 2020</title><link href="http://localhost:4000/reality/phd/weekly-recap/" rel="alternate" type="text/html" title="Week 4 Recap, 2020" /><published>2020-01-26T00:00:00-07:00</published><updated>2020-01-26T00:00:00-07:00</updated><id>http://localhost:4000/reality/phd/weekly-recap</id><content type="html" xml:base="http://localhost:4000/reality/phd/weekly-recap/">&lt;p&gt;This is going to the first of what I hope are many “weekly recaps”. Think of it
as kind of hybrid between a personal sprint (see: ) and freeform journaling.&lt;/p&gt;

&lt;h2 id=&quot;time-tracking&quot;&gt;Time Tracking&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; Monday was holiday, and we were moving.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Category&lt;/th&gt;
      &lt;th&gt;Time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Research&lt;/td&gt;
      &lt;td&gt;34 hr, 51 min&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reading&lt;/td&gt;
      &lt;td&gt;0 hr, 0 min&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Writing&lt;/td&gt;
      &lt;td&gt;Untracked&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;notable-accomplishments&quot;&gt;Notable Accomplishments:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Implemented Reinforcement Learning Synthetic environment using A2C framework&lt;/li&gt;
  &lt;li&gt;Moved back SLC and am setup for maximum attack!&lt;/li&gt;
  &lt;li&gt;Logistical graduation requirements squared&lt;/li&gt;
  &lt;li&gt;Paper Registered for ICS 2020&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-worked-well&quot;&gt;What Worked Well?&lt;/h2&gt;

&lt;p&gt;It’s definitely nice being back in the lab and having a place to go work,
particularly when my wife is around. When I work from home and she leaves from
work, it kind of feels like I’m still just at home and not in “work mode”. Having
an office to go to when she’s around is definitely needed to keep that focus.&lt;/p&gt;

&lt;h2 id=&quot;what-needs-improvement&quot;&gt;What Needs Improvement?&lt;/h2&gt;

&lt;p&gt;I was sloppy with some of my bullet journal tasks, and as a result a lot of stuff
either didn’t get done or was migrated. My goals need to be a little bit more
well thought through. If the goal is to setup a framework but it’s not clear what
the requirements are, the task should be setting up the requirements. More tasks
can always be added as they arise, rather than trying to make up stuff. Also need 
to be honest about the to-do list for this paper submission. The biggest “oof”
this week was missing a time sensitive email by a full 24 hours. Felt bad.&lt;/p&gt;

&lt;h2 id=&quot;what-could-make-you-happier&quot;&gt;What could make you happier?&lt;/h2&gt;

&lt;p&gt;Two main things bring me down: missing something critical and feeling like there’s
no time for fun. Organization is going to be key to make sure things don’t slip
through the cracks and bite me. Staying focused will help me ensure there IS
time to enjoy life, too.&lt;/p&gt;

&lt;h2 id=&quot;goals-for-next-week&quot;&gt;Goals for Next Week&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Take care when making daily goals&lt;/li&gt;
  &lt;li&gt;Finalize PhD committee&lt;/li&gt;
  &lt;li&gt;Finish revisions for ICS submission&lt;/li&gt;
  &lt;li&gt;Start writing MICRO submission&lt;/li&gt;
  &lt;li&gt;Detailed Goal list for MICRO submission&lt;/li&gt;
  &lt;li&gt;Measurements for simulation parameters&lt;/li&gt;
  &lt;li&gt;Progress on simulation environment&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Karl Taht</name></author><summary type="html">This is going to the first of what I hope are many “weekly recaps”. Think of it as kind of hybrid between a personal sprint (see: ) and freeform journaling.</summary></entry><entry><title type="html">Five Axioms for Productivity</title><link href="http://localhost:4000/reality/phd/11_rules/" rel="alternate" type="text/html" title="Five Axioms for Productivity" /><published>2020-01-21T00:00:00-07:00</published><updated>2020-01-21T00:00:00-07:00</updated><id>http://localhost:4000/reality/phd/11_rules</id><content type="html" xml:base="http://localhost:4000/reality/phd/11_rules/">&lt;p&gt;If you’re anything like me, you often find yourself reading or learning about
new techniques to improve yourself and your life. I think when you come across
these ideas they seem new and fresh and at face value always make a lot of sense.
The problem is that if you follow something like the self-improvement section on
Medium, you’ll be getting doses of new and fresh ideas everyday. One one hand,
this is really good. Things that are new keep us energized and excited to work
on ourselves. On the other hand, it really muddies the field in terms of what is 
important and what’s not. What really works versus what’s just interesting to 
consider. However, there’s one article that summarized some “Rules to Live By”
if you will, that I think are very powerful. I’m going to present them with my
own spin, and try to order it as well.&lt;/p&gt;

&lt;h2 id=&quot;1-do-the-most-important-thing-first&quot;&gt;1. Do the most important thing FIRST.&lt;/h2&gt;

&lt;p&gt;Each day, you choose the &lt;strong&gt;order&lt;/strong&gt; of when to do the things you need to do. Whether that’s taking
a shower and then having coffee, or grinding out an intensive task before checking
your email.  For me as a PhD student no longer taking classes, I have a ton of freedom in this. 
If I want to wake up at 1pm, spend the afternoon surfing YouTube, and start work
at 6pm, I theoretically have nothing stopping me on most days. However, I think
just reading that it’s pretty obvious that would be a terrible idea, but–why?&lt;/p&gt;

&lt;p&gt;Well, I personally don’t think there’s a concrete answer. But, I do feel strongly 
that once you reward yourself with something, you feel accomplished. You’re less
incentivized to continue to work. Whether than be going straight to a reward
(e.g. waking up and watching Netflix) or, doing a small task and feeling like
you’ve made progress on your day (e.g. sending that email when you really need
to code up a new algorithm).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The reality is, your day is defined by the most important thing you accomplish.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-dont-multi-task&quot;&gt;2. Don’t multi-task&lt;/h2&gt;

&lt;p&gt;People think that multi-tasking somehow improves our efficiency. It doesn’t. Have
you ever tried to scroll through Facebook while on the phone? You either missed
the conversation or you didn’t really read that post. People can’t think about
two things simulatenously. This is why I love the Pomodoro technique and wrote
and article dedicated to it. The whole point is you pick &lt;strong&gt;precisely&lt;/strong&gt; what you’re
going to focus on and do just that, no distractions.&lt;/p&gt;

&lt;h2 id=&quot;3-own-your-time&quot;&gt;3. Own your time&lt;/h2&gt;

&lt;p&gt;I feel like a lot of people have this mentality that hours in = progress out. In
reality, hours in &lt;strong&gt;times&lt;/strong&gt; intensity &lt;strong&gt;times&lt;/strong&gt; meaningfulness = progress out. When
we grind for too long, we lose focus both on what we’re doing and how we’re doing it.
This means you can’t just commit hours to something, you have to own those hours.&lt;/p&gt;

&lt;p&gt;There’s three main points for point number 3:&lt;/p&gt;

&lt;h3 id=&quot;spending-at-least-50-of-your-time-doing&quot;&gt;Spending at least 50% of your time doing&lt;/h3&gt;

&lt;p&gt;If you objectively look at your time, you probably spend a lot of time doing, well,
not productive things. Or at least, not directly productive things. Meetings, emails,
conversations, they are all necessary for progress and well being. But to truly
make an impact, you have to create. You have to do. Analyze your time and DO.&lt;/p&gt;

&lt;h3 id=&quot;give-yourself-time&quot;&gt;Give yourself time.&lt;/h3&gt;

&lt;p&gt;As much as productive time matters, so does recharge time. During the day, this
means taking a lunch break to take a step back from work. Make sure your focused
and energized and ready for the afternoon. This also means scheduling – and I 
really mean scheduling – time to do stuff you just LIKE. Stuff that doesn’t
add toward self-improvement, but just self-happiness. It could be Netflix and Chill,
videos games, taking a drive. Whatever it is, make time for you to be happy. If
you’re not enjoying this thing called life, there’s really no point anyway.&lt;/p&gt;

&lt;h3 id=&quot;track-your-time&quot;&gt;Track your time.&lt;/h3&gt;

&lt;p&gt;Want to really know much you’re working? How much Netflix you watch? Get a time
tracking app. There’s a lot of them out there, but I personally use “aTimeLogger”
which is super simple. You simple open the app and tap it when you start doing 
stuff. Be wary not to add too many categories or try to account for every minute
of the day. Instead figure out precise things that will help you answer questions
as to how you can better allocate your time. Maybe 20 hours of Netflix should be 
15 hours of Netflix and 5 hours of reading. Maybe the reason your so drained is
because you’re spending 60 hours at work and another 10 commuting. And don’t think
you have to dedicate a lot of retrospection to it either. Most days I just use it
to see, hey, have I really put in enough hours today? If not, how’s the week looking?&lt;/p&gt;

&lt;p&gt;Lastly, proceed with caution here. It’s easy to get sucked into a vortex of trying
to one-up yourself on how much time your spending on the things you “should be
spending time on”. While hours in are likely to improve your success, they’re
no guarantee of results. That’s why owning your time is 3, and doing what matters
most is first.&lt;/p&gt;

&lt;h2 id=&quot;4-write-it-down--on-paper&quot;&gt;4. Write it down – on Paper.&lt;/h2&gt;

&lt;p&gt;While I love typing and am a bit of a keyboard fanatic, I think there will always
be something borderline cerebral about physically writing with pen (or pencil) and
paper. Physically writing a check mark when you finish a pomodoro session or crossing
out an item on your to-do list. Besides that, the reality is we have shitty memories.&lt;/p&gt;

&lt;p&gt;Physically writing things down helps us remember. It puts things in perspective. 
When you write down a to-do list of what you’re going to do today and its 20 items
long, you physically realize it’s too much. Now 20 is arbitrary, but if you’ll
start doing this everyday you’ll realize what you can realistically accomplish in
one day.&lt;/p&gt;

&lt;p&gt;As of late, I like the bullet journal technique. I use it because it’s great way
to track short, medium, and long term goals. More than that, it’s flexible. You
can add sections that are relevant to you. Mine personally has a “Papers Read” 
section as well as “Things I love about my PhD” section. You can also track goals
easily and more. I highly recommending looking into it as it really took my 
existing journaling technique to the next level, and I’m really happy with it.&lt;/p&gt;

&lt;h2 id=&quot;5-discipline&quot;&gt;5. Discipline&lt;/h2&gt;

&lt;p&gt;Finally, the last piece of the puzzle is grit. You have to really want to 
improve yourself, and want it as often and as hard as possible. Believe in yourself,
and invest in yourself.&lt;/p&gt;</content><author><name>Karl Taht</name></author><summary type="html">If you’re anything like me, you often find yourself reading or learning about new techniques to improve yourself and your life. I think when you come across these ideas they seem new and fresh and at face value always make a lot of sense. The problem is that if you follow something like the self-improvement section on Medium, you’ll be getting doses of new and fresh ideas everyday. One one hand, this is really good. Things that are new keep us energized and excited to work on ourselves. On the other hand, it really muddies the field in terms of what is important and what’s not. What really works versus what’s just interesting to consider. However, there’s one article that summarized some “Rules to Live By” if you will, that I think are very powerful. I’m going to present them with my own spin, and try to order it as well.</summary></entry><entry><title type="html">Asynchronous Methods for Deep Reinforcement Learning (A3C)</title><link href="http://localhost:4000/research-papers/research/a3c/" rel="alternate" type="text/html" title="Asynchronous Methods for Deep Reinforcement Learning (A3C)" /><published>2020-01-16T09:57:00-07:00</published><updated>2020-01-16T09:57:00-07:00</updated><id>http://localhost:4000/research-papers/research/a3c</id><content type="html" xml:base="http://localhost:4000/research-papers/research/a3c/">&lt;p&gt;This paper presents a framework to perform asynchronous gradient descent for 
optimization of deep nerual networks in the scope of reinforcement learning
problems. Most importantly, this work presents the asynchronous advantage 
actor-critic framework (A3C), which is currently one of the state-of-the-art
frameworks for deep reinforcement learning.&lt;/p&gt;

&lt;p&gt;While neural networks are powerful universal function approximators making them
conceptually ideal for approximate reinforcement learning, they suffer from 
an inherit problem of instability and variance making convergence difficult to
achieve. As such, reinforcement learning has traditionally focused on off-policy
learning algorithms which were able to aggregate sufficient data during update
phases. However, this work changes that by providing a framework which reduces
resource requirements (for storing gradients) while maintaining reliability.&lt;/p&gt;

&lt;p&gt;The framework centralizes models on a single machine, reducing communication 
costs. Gradient descent can be done in a similar fashion to &lt;a href=&quot;https://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.pdf&quot;&gt;Hogwild!&lt;/a&gt;. Unlike
previous works, each simulated environment runs with different exploration policies
and different environments. Since the updates occur online, this reduces the 
likelihood that two parallel learners will have the same bias. The result
is a technique which can be applied to a variety of RL algorithms (one-step SARSA,
n-step Q-Learning, and advantage actor-critic). As a general approach toward
solving RL problems, A3C seems to be one of the most successful in general.&lt;/p&gt;

&lt;h3 id=&quot;the-a3c-algorithm&quot;&gt;The A3C Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/a3c_alg.png&quot; alt=&quot;A3C Algorithm&quot; /&gt;&lt;/p&gt;</content><author><name>Karl Taht</name></author><category term="Reinforcement Learning" /><category term="RL" /><category term="A3C" /><summary type="html">This paper presents a framework to perform asynchronous gradient descent for optimization of deep nerual networks in the scope of reinforcement learning problems. Most importantly, this work presents the asynchronous advantage actor-critic framework (A3C), which is currently one of the state-of-the-art frameworks for deep reinforcement learning.</summary></entry><entry><title type="html">Flow and the Pomodoro Study Technique</title><link href="http://localhost:4000/reality/phd/pomodoro/" rel="alternate" type="text/html" title="Flow and the Pomodoro Study Technique" /><published>2020-01-15T00:00:00-07:00</published><updated>2020-01-15T00:00:00-07:00</updated><id>http://localhost:4000/reality/phd/pomodoro</id><content type="html" xml:base="http://localhost:4000/reality/phd/pomodoro/">&lt;p&gt;One thing about studying, or really, any kind of working that has limited human
interaction faces one key challenge: staying focused. I think that’s true now 
more than ever with cell phones, social media, email. Everything is trying to 
pull us away from what we’re working on right now. We can make to-do list’s and
stay organized, but eventually we will have to sit down and simply use our mind.&lt;/p&gt;

&lt;p&gt;The first thing is – don’t discredit your to-lists and organizations. I keep
a journal, more specifically, a bullet journal, to track all my daily, monthly,
and longer term goals. Once you have these tasks distilled to a reasonable level,
you at least know where you focus &lt;strong&gt;should&lt;/strong&gt; be, and that’s step one. Now, how
do you force yourself to focus?&lt;/p&gt;

&lt;h2 id=&quot;flow&quot;&gt;Flow&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/flow.png&quot; alt=&quot;Challenge vs Ability&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There’s this really interesting chart that demonstrates this notion of “flow”, 
when we are focused on what we are doing and happy, and by extension, most 
productive. In reality, its really hard to achieve this state. Maybe your 
current projectis boring because it’s too easy. Maybe it’s intimidating and 
even starting stresses you out. So, is there a way we can force ourselves into
flow?&lt;/p&gt;

&lt;h2 id=&quot;the-pomodoro-technique&quot;&gt;The Pomodoro Technique&lt;/h2&gt;

&lt;p&gt;The Pomodoro techinque is exceedingly simple, and involves disecting time into
manageable increments. You’ll work in 25-minute “sprints” with short breaks, and
after 4 of these sprints, you’ll take a longer break. Let’s lay it out:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Select the task you want to work on. If you have your to-do list, this should
be easy.&lt;/li&gt;
  &lt;li&gt;Set a 25-minute timer. Eliminate all disractions and dive into the task at 
hand, and nothing else. No checking Facebook, emails, messages, etc. You work
until the timer goes off. The Pomodoro begins.&lt;/li&gt;
  &lt;li&gt;Physically WRITE a check-mark down on the paper. You’ve completed a Pomodoro.&lt;/li&gt;
  &lt;li&gt;Take a short break for 3-5 minutes. Grab yourself a drink, check those IMs. 
Do something NOT work related.&lt;/li&gt;
  &lt;li&gt;Every 4 pomodoros, take a longer break like 20-30 minutes. I call a group
of 4 pomodoros a “pomodoro session”.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I think what I love about this technique is how simple it is. One of my “to-do”
items every day now includes “Pomodoro Sessions x …” based on how much time I 
think I have to work that day. Now I’ll be honest, sessions 1 and 2 usually go
really well for me, but the 3rd session is usually a significantly harder.&lt;/p&gt;

&lt;p&gt;Full disclosure, I used this technique a lot in early 2019 when I first started
working completely from home, and had a good amount of success. I completely
forgot about it however, after returning from my internship. I only recently 
recalled and it put it back to use, and I’m really pleased with the results. 
Time to hit 2020 running!&lt;/p&gt;</content><author><name>Karl Taht</name></author><summary type="html">One thing about studying, or really, any kind of working that has limited human interaction faces one key challenge: staying focused. I think that’s true now more than ever with cell phones, social media, email. Everything is trying to pull us away from what we’re working on right now. We can make to-do list’s and stay organized, but eventually we will have to sit down and simply use our mind.</summary></entry><entry><title type="html">Paper Rejection Reflection</title><link href="http://localhost:4000/reality/phd/rejected/" rel="alternate" type="text/html" title="Paper Rejection Reflection" /><published>2020-01-14T00:00:00-07:00</published><updated>2020-01-14T00:00:00-07:00</updated><id>http://localhost:4000/reality/phd/rejected</id><content type="html" xml:base="http://localhost:4000/reality/phd/rejected/">&lt;p&gt;Today, I found out my submission to the ISPASS conference was rejected. The
strange thing about it is, I mostly just feel confused. How should you really 
feel when a your work is rejected? Discredited? Angry? Confused? For me, I just
feel blank.&lt;/p&gt;

&lt;p&gt;You see, at the University of Utah in the Computer Science department, PhD 
candidates are expected to output at least 3 top-tier publications before defending
and graduating. In reality, that translates to something like 5-10 submissions
of varying caliber throughout the program. While I think I’ve submitted something
like 5 works, this submission was my 2nd &lt;strong&gt;major&lt;/strong&gt; work, in that, I really 
wanted/needed it to get accepted.&lt;/p&gt;

&lt;p&gt;The odd thing is, the rejection felt expected. Objectively, I defend the paper. 
I think it should have gotten in. It had novelty. It had results. It was cohesive. 
But in the end the results weren’t good &lt;strong&gt;enough&lt;/strong&gt; for the reviewers it seems.&lt;/p&gt;

&lt;p&gt;One thing I’ve found about research in general, there are really two high-level
avenues to research. There’s work that focuses on improving industry scale solutions,
research that optimizes the current reality. In general, these types of works will net 
incremental improvement. Intuitively, 
if it’s a problem that really matters many people will be focused on solving that
problem, so the existing solution is probably pretty good. Nevertheless, the
incremental 1\% improvement results in positive impact on 99\% of users.&lt;/p&gt;

&lt;p&gt;The alternative type of research, is the niche but truly novel. This is the type
of work where  a solution improves the current state-of-the-art by many times 
over. The novelty and improvement shows promise in a field either forgotton or
never before seen. With this type of work, there’s two possible implications. 
People realize that this novel area is worth further investigation, and it opens
up a new domain of research, or, it fades into nothing.&lt;/p&gt;

&lt;p&gt;On the rare occassion, a work will vastly improve the state-of-the-art AND be
impactful at a large scale. These are the “big name works” if you will,
the ones that made people famous and impacted the world. These 
types of works which hit on both levels require a real tenacity for the field, 
in addition to brilliance.&lt;/p&gt;

&lt;p&gt;I think the reason why I feel rather detached from the whole situation is that
when I look at my work as well as the work of most of my colleagues, I feel we
slot nicely into either the “real” or “novel”. For example, my interest in Spark
compute engine improvements are very real – changes could quickly make it to 
industry and effect thousands of servers. On the other hand, my colleagues’ work
is novel. They are designing completely new computer architectures to optmize
neural networks. However, the likeliihood that their chip will be fabricated is 
low, and it’s even less likely that the chip design will be widely adopted into
industry.&lt;/p&gt;

&lt;p&gt;Now, my point isn’t to argue which is better or more interesting – I think that’s
clearly in the eyes of the beholder – but fundamentally, I think we can become
disconnected from importance of our work as researchers. Does what we do really
matter if it’s just 1% improvement or a niche design? Clearly, the answer is yes.
Those 1% improvements stack up from all over the world, and those niche designs
continue to improve until they can no longer be ignored. But simple knowledge
doesn’t override emotional response.&lt;/p&gt;

&lt;p&gt;And I think that’s the real crux: the paper rejection pushes me to believe my
incremental improvement is just that. It distances me from believing my work
matters and leaves me feeling blank. While I don’t like ending on such a negative
note, I think I must. Social media promotes only sharing the best aspects of life,
but a big part of reality that is ignored is the lows. This is a low, and that’s okay.&lt;/p&gt;</content><author><name>Karl Taht</name></author><summary type="html">Today, I found out my submission to the ISPASS conference was rejected. The strange thing about it is, I mostly just feel confused. How should you really feel when a your work is rejected? Discredited? Angry? Confused? For me, I just feel blank.</summary></entry><entry><title type="html">Multi-Resource Packing for Cluster Schedulers (Tetris)</title><link href="http://localhost:4000/research-papers/research/multi-resource-packing-for-cluster/" rel="alternate" type="text/html" title="Multi-Resource Packing for Cluster Schedulers (Tetris)" /><published>2020-01-08T09:57:00-07:00</published><updated>2020-01-08T09:57:00-07:00</updated><id>http://localhost:4000/research-papers/research/multi-resource-packing-for-cluster</id><content type="html" xml:base="http://localhost:4000/research-papers/research/multi-resource-packing-for-cluster/">&lt;p&gt;Authors: Robert Grandl, Ganesh Anathanarayanan, Srikanth Kandula, Sriram Rao, Aditya Akella&lt;/p&gt;

&lt;p&gt;Venue: SIGCOMM 2014&lt;/p&gt;

&lt;p&gt;Cluster level scheduling is a complex topic in which performance, fairness, and hard constraints must all be considered. Fundamentally, a perfectly fair solution sacrifices performance. This work presents a resource-aware cluster scheduling scheme which maximizes performance and includes additional parameters to balance fairness requirements. &lt;!--more--&gt; For simplicity, I will divide the discussion into two sections: the central idea and additional heuristics.&lt;/p&gt;

&lt;p&gt;Tetris performs scheduling by analyzing jobs resource requirements in terms of CPUs, memory, disk I/O, and network usage. Each job, task (a subset of a job), and machine is assigned a resource vector. To determine the optimal positioning of a task, a heuristic is used which takes the dot product of the job’s resource requirements vs a candidates available resources. The machine with the maximum dot product is selected to place the job. To incorporate fairness into the approach, the number of candidate jobs can be adjusted. Maximizing fairness will only place jobs in the global queue order, while maximizing performance will consider all jobs in the queue.&lt;/p&gt;

&lt;p&gt;In addition to the basic setup, Tetris also includes additional heuristic properties to ensure no low-hanging fruit is left on the table. Firstly, shortest remaining time first (SRFT) algorithm is incorporated into the scheduling calculations, such that dot products are weighted to favor jobs nearly completions. The next optimization comes from the nature of map-reduce and DAG dependencies. Again, when a job is nearing the end of a stage, it’s tasks a favored so that it can begin the next stage sooner. The last significant optimization is regarding the “remote penalty”. When a job is scheduled away from data locality, it’s network requirements will increase. Thus, jobs which cause this are assigned a penalty (note this part is a bit vague in the details from my reading).&lt;/p&gt;

&lt;p&gt;Overall, exceptional gains are achieved of a 40% improvement in job completion time and 41% improvement in job makespan (the total time for all jobs to complete). This occurs with a minimal impact in fairness, where about 6% jobs are delayed more than 10%. It would have been nice to see an S-curve of job improvements to illustrate the details more clearly, but nevertheless fairness seems to suffer marginally.&lt;/p&gt;</content><author><name>Karl Taht</name></author><category term="cluster scheduling" /><category term="spark" /><category term="resource allocation" /><category term="tetris" /><category term="cluster computing" /><category term="map-reduce" /><category term="resource-aware scheduling" /><category term="resource management" /><summary type="html">Authors: Robert Grandl, Ganesh Anathanarayanan, Srikanth Kandula, Sriram Rao, Aditya Akella</summary></entry><entry><title type="html">Sparrow: Distributed, Low Latency Scheduling</title><link href="http://localhost:4000/research-papers/research/sparrow-distributed-low-latency/" rel="alternate" type="text/html" title="Sparrow: Distributed, Low Latency Scheduling" /><published>2019-12-18T10:15:00-07:00</published><updated>2019-12-18T10:15:00-07:00</updated><id>http://localhost:4000/research-papers/research/sparrow-distributed-low-latency</id><content type="html" xml:base="http://localhost:4000/research-papers/research/sparrow-distributed-low-latency/">&lt;p&gt;Authors: Kay Ousterhout, Patrick Wendell, Matei Zaharia, Ion Stoica
Venue:    SOSP 2013&lt;/p&gt;

&lt;p&gt;This work presents Sparrow, a stateless, decentralized scheduler for cluster scheduling. The scheduling component uses two key ideas: batch sampling and late binding. Batch sampling is an extension of the power of two choices [1], which shows that the “tail” can quickly be cut off by simply sampling between two machines versus randomly selecting one. Batch sampling generalizes this by sampling dm machines, and placing the m tasks on the machine with the lowest load. Late binding delays the actual task transfer until the machine is ready to process the request. This can be thought of as having a place holder in the worker’s queue, and when the worker is finally ready to process it, the actual task is transferred from the scheduler to the worker. This avoids having to rely on inaccurate metrics such as queue depth. Each worker maintains its “instance” of Sparrow, which uses multiple queues to enforce global policies. Additionally, Sparrow is orthogonal to straggler mitigation techniques, and they could be applied in conjunction.&lt;/p&gt;

&lt;p&gt;Sparrow does have the following limitations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Limitations of placement constraints: “my job should not be run on machine where User X’s jobs are run”&lt;/li&gt;
  &lt;li&gt;No bin-packing (for performance, I assume)&lt;/li&gt;
  &lt;li&gt;No gang scheduling&lt;/li&gt;
  &lt;li&gt;No preemption, so by extension, struggles with (highly) heterogeneous tasks&lt;/li&gt;
  &lt;li&gt;Despite the limitations, the end result is extremely impressive – within 12% of an optimal scheduler. And the optimal scheduler is very idealistic (assumes no transfer time).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[1]: Mitzenmacher, Michael. “The power of two choices in randomized load balancing.” IEEE Transactions on Parallel and Distributed Systems 12.10 (2001): 1094-1104.&lt;/p&gt;</content><author><name>Karl Taht</name></author><category term="cluster scheduling" /><category term="spark" /><category term="ec2" /><category term="scheduling" /><category term="cluster computing" /><category term="latency" /><category term="tpc" /><summary type="html">Authors: Kay Ousterhout, Patrick Wendell, Matei Zaharia, Ion Stoica Venue: SOSP 2013</summary></entry><entry><title type="html">SOSA: Self-Optimizing Learning with Self-Adaptive Control for Hierarchical System-on-chip Management</title><link href="http://localhost:4000/research-papers/research/sosa-self-optimizing-learning-with-self/" rel="alternate" type="text/html" title="SOSA: Self-Optimizing Learning with Self-Adaptive Control for Hierarchical System-on-chip Management" /><published>2019-12-14T18:19:00-07:00</published><updated>2019-12-14T18:19:00-07:00</updated><id>http://localhost:4000/research-papers/research/sosa-self-optimizing-learning-with-self</id><content type="html" xml:base="http://localhost:4000/research-papers/research/sosa-self-optimizing-learning-with-self/">&lt;p&gt;Authors: Bryan Donyanavard, Tiago Muck, Amir M. Rahmani, Nikil Dutt, Armin Sadighi, Florian Mauer, Andreas Herkersdorf&lt;/p&gt;

&lt;p&gt;Venue: MICRO 2019&lt;/p&gt;

&lt;p&gt;This work presents a control theory / reinforcement learning hybrid approach to solve online parameter tuning for SoC’s called SOSA. While controllers are typically known for being light weight, and RL expensive, the authors build the hierarchy opposite from what you might expect. The RL models, Learning Classifier Tables (LCTs), are used as low-level controllers, and high level supervisor controller uses Supervisory Control Theory (SCT). The SCT controls a high-level system model abstraction, which must be consistent with the low-level system “as defined in the Ramadge-Wonham control mechanism” [1]. This assumption requires further investigation.&lt;/p&gt;

&lt;p&gt;LCTs are a simpler RL algorithm compared to today’s deep neural network approaches. They utilize rule-based learning to to target an objective function, which may be multi-variate. The error between the objective value and achieved value (via the action) is used to calculate error, which is used as the reward signal for the agent. Note that the error also requires the max performance as a scaling factor. For IPC this is a reasonable, but may not be the case for other metrics.&lt;/p&gt;

&lt;p&gt;Evaluation is performed both in simulation and on an FPGA which implements SPARCv8 architecture. In the experiments, the authors tune DVFS and task migration. Load distribution is also a very odd target, particularly because CFS already solves the load balancing in hierarchical fashion, and utilizes the same metric of CPU utilization to perform the balancing. Results indicate that after a few seconds the models converge to an optimum, and can re-converge after a new task is added. However, I felt that the efficacy of the approach was hard to evaluate given the unusual benchmark setup and simulation framework. How much better SOSA is that existing real-world load balancing and firmware governors (which consist of both power saving and performance modes) is unclear.&lt;/p&gt;

&lt;p&gt;Objectively, I have a few issues with this paper. One one hand, it’s a novel approach to use both control theory and reinforcement learning in a hybrid solution to solve the knob tuning problem. However, the motivation and results section seem to disagree with themselves. One of the benefits of RL is that lack of a requirement for specifying a particular target, and simply aiming to minimize or maximize a value, yet the use of RL in this case is to minimize error … while hitting a particular target. Moreover, if the supervisor is simply specifying “the operating frequency of each core”, then what exactly are the LCTs doing? Finally, the hardware cost of the approach–and why evaluation is FPGA/Simulation based–seems high (~9.6%), about 2% of which is due to the LCT’s. Is that worth it for 5ms response time? The work is very interesting, but the application of RL seems misplaced. As the number of knobs scale, RL is known to have variance issues. I don’t see how the LCT’s will stand up in terms of convergence rate and hardware/computational complexity as the number of knobs scale. And what happens when a system is overloaded and constantly shuffling tasks?&lt;/p&gt;

&lt;p&gt;[1] Brandin, Bertil A., and W. Murray Wonham. “Supervisory control of timed discrete-event systems. IEEE Transactions on Automatic Control (1994): 329-342.&lt;/p&gt;</content><author><name>Karl Taht</name></author><category term="control theory" /><category term="LCT" /><category term="reinforcement learning" /><category term="dynamic hardware" /><category term="autotuning" /><summary type="html">Authors: Bryan Donyanavard, Tiago Muck, Amir M. Rahmani, Nikil Dutt, Armin Sadighi, Florian Mauer, Andreas Herkersdorf</summary></entry></feed>