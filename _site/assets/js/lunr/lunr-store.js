var store = [{
        "title": "SOSA: Self-Optimizing Learning with Self-Adaptive Control for Hierarchical System-on-chip Management",
        "excerpt":"Authors: Bryan Donyanavard, Tiago Muck, Amir M. Rahmani, Nikil Dutt, Armin Sadighi, Florian Mauer, Andreas Herkersdorf Venue: MICRO 2019 This work presents a control theory / reinforcement learning hybrid approach to solve online parameter tuning for SoC’s called SOSA. While controllers are typically known for being light weight, and RL...","categories": ["research-papers","research"],
        "tags": ["control theory","LCT","reinforcement learning","dynamic hardware","autotuning"],
        "url": "http://localhost:4000/research-papers/research/sosa-self-optimizing-learning-with-self/",
        "teaser":null},{
        "title": "Sparrow: Distributed, Low Latency Scheduling",
        "excerpt":"Authors: Kay Ousterhout, Patrick Wendell, Matei Zaharia, Ion Stoica Venue: SOSP 2013 This work presents Sparrow, a stateless, decentralized scheduler for cluster scheduling. The scheduling component uses two key ideas: batch sampling and late binding. Batch sampling is an extension of the power of two choices [1], which shows that...","categories": ["research-papers","research"],
        "tags": ["cluster scheduling","spark","ec2","scheduling","cluster computing","latency","tpc"],
        "url": "http://localhost:4000/research-papers/research/sparrow-distributed-low-latency/",
        "teaser":null},{
        "title": "Multi-Resource Packing for Cluster Schedulers (Tetris)",
        "excerpt":"Authors: Robert Grandl, Ganesh Anathanarayanan, Srikanth Kandula, Sriram Rao, Aditya Akella Venue: SIGCOMM 2014 Cluster level scheduling is a complex topic in which performance, fairness, and hard constraints must all be considered. Fundamentally, a perfectly fair solution sacrifices performance. This work presents a resource-aware cluster scheduling scheme which maximizes performance...","categories": ["research-papers","research"],
        "tags": ["cluster scheduling","spark","resource allocation","tetris","cluster computing","map-reduce","resource-aware scheduling","resource management"],
        "url": "http://localhost:4000/research-papers/research/multi-resource-packing-for-cluster/",
        "teaser":null},{
        "title": "Paper Rejection Reflection",
        "excerpt":"Today, I found out my submission to the ISPASS conference was rejected. The strange thing about it is, I mostly just feel confused. How should you really feel when a your work is rejected? Discredited? Angry? Confused? For me, I just feel blank. You see, at the University of Utah...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/rejected/",
        "teaser":null},{
        "title": "Flow and the Pomodoro Study Technique",
        "excerpt":"One thing about studying, or really, any kind of working that has limited human interaction faces one key challenge: staying focused. I think that’s true now more than ever with cell phones, social media, email. Everything is trying to pull us away from what we’re working on right now. We...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/pomodoro/",
        "teaser":null},{
        "title": "Asynchronous Methods for Deep Reinforcement Learning (A3C)",
        "excerpt":"This paper presents a framework to perform asynchronous gradient descent for optimization of deep nerual networks in the scope of reinforcement learning problems. Most importantly, this work presents the asynchronous advantage actor-critic framework (A3C), which is currently one of the state-of-the-art frameworks for deep reinforcement learning. While neural networks are...","categories": ["research-papers","research"],
        "tags": ["Reinforcement Learning","RL","A3C"],
        "url": "http://localhost:4000/research-papers/research/a3c/",
        "teaser":null},{
        "title": "Five Axioms for Productivity",
        "excerpt":"If you’re anything like me, you often find yourself reading or learning about new techniques to improve yourself and your life. I think when you come across these ideas they seem new and fresh and at face value always make a lot of sense. The problem is that if you...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/11_rules/",
        "teaser":null},{
        "title": "Week 4 Recap, 2020",
        "excerpt":"This is going to the first of what I hope are many “weekly recaps”. Think of it as kind of hybrid between a personal sprint (see: ) and freeform journaling. Time Tracking Note: Monday was holiday, and we were moving. Category Time Research 34 hr, 51 min Reading 0 hr,...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/weekly-recap/",
        "teaser":null},{
        "title": "Reinforcement Learning Resources",
        "excerpt":"Books     Reinforcement Learning: An Introduction (Sutton and Barto)   Lectures     Stanford, Lecture 14: Reinforcement Learning            Great overview of all RL basics, closely follows Sutton and Barto’s text       Lecture       Slides           Code     Stable Baselines            This is my personal favorite respitory for RL algorithms       Documentation available           Practical Implementions of OpenAI Gym Algorithms  ","categories": ["phd"],
        "tags": [],
        "url": "http://localhost:4000/phd/reinforcement-learning/",
        "teaser":null},{
        "title": "Accelerating Distributed Reinforcement Learning with In-Switch Computing",
        "excerpt":"Venue: ISCA 2019 Authors: Youjie Li, Iou-Jen Li, Yifan Yuan, Deming Chen, Alexander Schwing, Jian Huang This paper presents iSwitch, an in-switch accelerator which improves the performance of distributed machine learning training – specifically reinforcement learning. While reinforcement learning (RL) models are typically small compared to other DNN applications, they...","categories": ["research-papers","research"],
        "tags": ["distributed machine learning","reinforcement learning","in-switch accelerator"],
        "url": "http://localhost:4000/research-papers/research/iswitch/",
        "teaser":null},{
        "title": "January 2020 Recap",
        "excerpt":"Well, since I’m wrapping up weeks, I might as well wrap up months too, right? Time Tracking This is going to be a bit messy since I’ve only recently started being more diligent, so bear in mind – a lot of missing hours! Category Time Notes Research 106 hr, 18...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/january-recap/",
        "teaser":null},{
        "title": "Large-scale Cluster Management at Google with Borg",
        "excerpt":"This paper provides a high-level overview of Google’s cluster manager: Borg. The paper describes the data warehouse environment, Borg’s architecture, and discusses performance related choices in more detail. Google’s Datacenter Environment Services and user work is submitted to Google clusters via notion of “jobs”, which consistent of one or more...","categories": ["research-papers","research"],
        "tags": ["Cluster management","borg","scale","datacenter","datawarehouse"],
        "url": "http://localhost:4000/research-papers/research/borg/",
        "teaser":null},{
        "title": "Week 5 Recap, 2020",
        "excerpt":"Metrics Tracking Going to track time and some other hard metrics. We’ll see how many I keep. Category This Week Last Week Notes Work &gt; Research &gt; Reading 44 hr, 33 min 41 hr, 57 min 2 hr, 35 min 34 hr, 51 min Untracked untracked + 9.7 hours Reading...","categories": ["reality","phd"],
        "tags": [],
        "url": "http://localhost:4000/reality/phd/weekly-recap/",
        "teaser":null}]
