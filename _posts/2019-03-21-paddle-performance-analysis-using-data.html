---
layout: post
title: 'PADDLE: Performance Analysis using a Data-Driven Learning Environment'
date: '2019-03-21T12:45:00.000-07:00'
author: Karl Taht
tags:
- data center
- machine learning
- performance counters
- HPC
- autotuning
- performance monitoring
- feature extraction
- performance modeling
modified_time: '2019-03-21T12:45:23.395-07:00'
blogger_id: tag:blogger.com,1999:blog-2670908301789336410.post-1968837009210847573
blogger_orig_url: https://researchdoneright.blogspot.com/2019/03/paddle-performance-analysis-using-data.html
---

<br />Authors: Jayaraman Thiagarajan, Rushil Anirdh, Bhavya Kaikhura, Nikhil Jain, Tanzima Islam, Abhinav Bhatele, Jae-Seung Yeom, Todd Gamblin<br />Venue: <span style="font-family: Times, Times New Roman, serif;">I<span style="background-color: white; color: #222222;">EEE International Parallel and Distributed Processing Symposium (IPDPS)</span></span><br /><span style="font-family: Times, Times New Roman, serif;"><span style="background-color: white; color: #222222;"><br /></span></span>In the scope of HPC, machine learning is gaining increased traction to add in performance analysis and tuning. However, this approach includes a pipeline of data collection, data pre-processing, various machine learning algorithm testing, tuning, and then finally trying to understand the model. The paper states that while this process is repetitive, rarely can insights be reused from one domain to another. To address this void, the propose PADDLE.<br /><br />PADDLE has three key steps: deep feature extraction, model design, and visualization. The first step allows users to throw extensive amounts of data at the problem, and an automated solutions determines the key inputs, mapping them to a new feature space. The next step in paddle automatically tests a number of machine learning algorithms, selecting one which minimizes complexity and maximizes accuracy. Finally, the third step provides a visualization which provides insights as to the key inputs into the model, as well as showing relations between various sources.<br /><br />PADDLE's generalized approach is tested on several domain specific areas, finding PADDLE to out-perform tailored approaches in several cases. My personal take away from this paper is that deep feature extraction seems to be a key component of what makes the pipeline successful, and I look forward to doing more reading in this specific domain. The visualization is a nice addition, but again, seems to be rooted in the feature extraction. The model design, or central component, is rather light in the text in terms of implementation. They use a notion of bias and variance in analyzing various&nbsp; models, but again, note that much of the model success is tied to feature extraction. Overall, good insights into how domain specific problems can be generalized. Nevertheless, expertise will always be required in extracting features and selecting the right training data.<br /><br /><a href="https://www.osti.gov/servlets/purl/1455398">Full Paper</a>